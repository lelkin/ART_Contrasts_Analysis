# normal, lognormal, cauchy, double exponential, 3dft distr with diff means but same scale
if(testType %in% c(101, 111, 132, 151, 141)){
ms_ms = 0
ms_ss = 1
currMeanSeed = rnorm(1, mean=ms_ms, sd=ms_ss)
sdSeed = 1
if(!infoFileWritten){
cat(sprintf("currMeanSeed = rnorm(1, mean=%s, sd=%s), sdSeed = %s",
ms_ms, ms_ss, sdSeed),
file=infoFilename,append=TRUE,sep="\n")
}
}
# normal, lognormal, cauchy, exponetial, double exponential, 3 df t, with diff mean seeds and diff sd seeds
if(testType %in% c(100, 110, 120, 130, 140, 150)){
ms_ms = 0
ms_ss = 1
ss_ms = 0
ss_ss = 1
currMeanSeed = rnorm(1, mean=ms_ms, sd=ms_ss)
sdSeed = abs(rnorm(1, mean = ss_ms, sd=ss_ss))
if(!infoFileWritten){
cat(sprintf("currMeanSeed = rnorm(1, mean=%s, sd=%s), sdSeed = abs(rnorm(1, mean = %s, sd=%s))",
ms_ms, ms_ss, ss_ms, ss_ss),
file=infoFilename,append=TRUE,sep="\n")
}
}
# cauchy with diff mean seeds and sd seeds
# mean seed and sd seed pulled from normal with mean 10, sd 2
if(testType %in% c(131)){
ms_ms = 10
ms_ss = 5
ss_ms = 0
ss_ss = 1
currMeanSeed = rnorm(1, mean=ms_ms, sd=ms_ss)
sdSeed = abs(rnorm(1, mean = ss_ms, sd = ss_ss))
if(!infoFileWritten){
cat(sprintf("currMeanSeed = rnorm(1, mean=%s, sd=%s), sdSeed = abs(rnorm(1, mean = %s, sd=%s))",
ms_ms, ms_ss, ss_ms, ss_ss),
file=infoFilename,append=TRUE,sep="\n")
}
}
# 3df t dist with different noncentrality parameters and same scale, just bigger means
if(testType == 142){
ms_ms = 10
ms_ss = 2
currMeanSeed = rnorm(1, mean=ms_ms, sd=ms_ss)
sdSeed = 1
if(!infoFileWritten){
cat(sprintf("currMeanSeed = rnorm(1, mean=%s, sd=%s)", ms_ms, ms_ss),
file=infoFilename,append=TRUE,sep="\n")
}
}
# log seed values
# add mean seed to logs
currMeanSeedName = paste("Ms", conditionNum, sep="")
metaLogRow[[currMeanSeedName]] = currMeanSeed
# add sd seed to logs
currSdSeedName = paste("SDs", conditionNum, sep="")
metaLogRow[[currSdSeedName]] = sdSeed
# add NA entries for Mi and SDi, will add actual values later
# NOTE: need to do this here so order of metaLogRow is correct
metaLogRow[[paste("M", conditionNum, sep="")]] = NA
metaLogRow[[paste("SD", conditionNum, sep="")]] = NA
return(list("latentMean" = currMeanSeed, "latentMeanSd" = ms_ss, "trueSd" = sdSeed, "metaLogRow" = metaLogRow))
}
# add random offsets for random intercepts to latent mean column in data
# Returns: list("data" = data, "metaLogRow" = metaLogRow)
addRandomIntercepts = function(data, metaLogRow, latentMeanSd){
# if random intercepts: for each participant get one value from N(0, p*latentMeanSd)
# where p is some proportion
# add this value to all latent means for that participant
# get proportion
pVec = c(0.1, 0.5, 0.9)
# use data frame number to choose proportion
dataFrameNum = metaLogRow[["Data_Set"]]
p = pVec[dataFrameNum %% length(pVec) + 1]
# get s
s = p*latentMeanSd
# get offset for each participant
numSubjects = max(data[["S"]])
interceptOffsets = rnorm(numSubjects, mean = 0, sd = s)
# log s and p
metaLogRow[["offsetProp"]] = p
metaLogRow[["offsetSd"]] = s
# add offset for each participant to all their latent means
data["latentMean"] = adply(data, 1, function(x) x[["latentMean"]] + interceptOffsets[[x[["S"]]]], .expand=FALSE, .id=NULL)
# return
return(list("data" = data, "metaLogRow" = metaLogRow))
}
# applies link function to latent mean. puts result in column named mu
applyLinkFunction = function(data){
#testTypes = c(0,10,20,30,100,101,110,111,120,130,131,132,141,142,150,151)
# normalDistrs = c(0,100,101) # linear
# logNormalDistrs = c(10,110,111) # linear (rlnorm does it for us)
# exponentialDistrs = c(20,120) # log link (ie use exp) and 1/mu = rate
# cauchyDistrs = c(30,130,131,132) # linear
# threeDfTDistrs = c(140,141,142) # linear
# doubleExponentialDistrs = c(150,151) # linear
# mu = exp(latentMean). then put 1/mu in mu column because exponential takes in rate
if(testType %in% exponentialDistrs){
# log transform latent mean
data = data %>% mutate(mu = 1.0/exp(latentMean), latentMean = NULL)
}
# linear link
else{
data = data %>% mutate(mu = latentMean, latentMean = NULL)
}
data
}
# data has rows trueSd and mu
# make new row Y = distr(mu, trueSd)
# where distr depends on testType
# Returns: data with Y  values in each row
getNewY = function(data){
# defined globally
# normalDistrs = c(0,100,101) DONE
# logNormalDistrs = c(10,110,111) DONE
# exponentialDistrs = c(20,120) DONE
# cauchyDistrs = c(30,130,131,132) DONE
# threeDfTDistrs = c(40,140,141,142)
# doubleExponentialDistrs = c(150,151)
if(testType %in% normalDistrs){
data[["Y"]] = apply(data, 1, function(x) rnorm(1, mean = x[["mu"]], sd = x[["trueSd"]]))
if(!infoFileWritten){
cat("sample distr: rnorm(1, mean = mu, sd = trueSd)",
file=infoFilename,append=TRUE, sep="\n")
}
}
if(testType %in% logNormalDistrs){
data[["Y"]] = apply(data, 1, function(x) rlnorm(1, meanlog = x[["mu"]], sdlog = x[["trueSd"]]))
if(!infoFileWritten){
cat("sample distr: rlnorm(1, meanlog = mu, sdlog = trueSd)",
file=infoFilename,append=TRUE, sep="\n")
}
}
# data[["mu"]] is really rate for exp distrs.
# data[["trueSd"]] has default value 1.
if(testType %in% exponentialDistrs){
data[["Y"]] = apply(data, 1, function(x) rexp(1, rate = x[["mu"]]))
if(!infoFileWritten){
cat("sample distr: rexp(1, rate = mu)\n Note: column name in data frame was mu, but it was the computed rate",
file=infoFilename,append=TRUE, sep="\n")
}
}
if(testType %in% cauchyDistrs){
data[["Y"]] = apply(data, 1, function(x) rcauchy(1, location = x[["mu"]], scale = x[["trueSd"]]))
if(!infoFileWritten){
cat("sample distr: rcauchy(1, location = mu, scale = trueSd)",
file=infoFilename,append=TRUE, sep="\n")
}
}
if(testType %in% threeDfTDistrs){
data[["Y"]] = apply(data, 1, function(x) rTF(1, mu = x[["mu"]], sigma = x[["trueSd"]], nu = 3))
if(!infoFileWritten){
cat("sample distr: rTF(1, mu = mu, sigma = trueSd, nu = 3)",
file=infoFilename,append=TRUE, sep="\n")
}
}
if(testType %in% doubleExponentialDistrs){
data[["Y"]] = apply(data, 1, function(x) rdexp(1, location = x[["mu"]], scale = x[["trueSd"]]))
if(!infoFileWritten){
cat("sample distr: rdexp(1, location = mu, scale = trueSd)",
file=infoFilename,append=TRUE, sep="\n")
}
}
# remove mu and trueSd columns
data = data %>% mutate(mu = NULL, trueSd = NULL)
return(data)
}
# make data frame for this one data set
# RETURNS: data frame for single data set
#          metadata for log file (metaLogRow)
makeOneDataSet = function(infoFilename, dataFrameNum, between, testType, conditionsDf, numConditions, numResponsesPerCondition, condStrNumMap){
data = data.frame()
# temp row has log info that will be used by every row in log
metaLogRow = list("Data_Set" = dataFrameNum, "ART_Con_Warning" = 0, "Omnibus_ART_Warning" = 0, "Num_Responses_per_Condition" = numResponsesPerCondition, "Random_Seed" = randomSeed) # Starting row of log data frame.
metaLogRow[["BW"]] = if(between) "B" else "W"
# add B or W to metaLogRow
# latent mean sd is same for all conditions in one df (actually same for all conditions in one test type)
# will update with different value from getLatentMeanAndSd if changed
latentMeanSd = 1
# get y values for each condition and add to data.
for(i in 1:numConditions){
# replicate this condition correct number of times
currConditionRow = as.vector(conditionsDf[i,])
currConditionDf = do.call("rbind", replicate(numResponsesPerCondition, currConditionRow, simplify = FALSE))
# add subject ids
if(between){
startId = numResponsesPerCondition*(i-1) + 1
endId = startId + numResponsesPerCondition - 1 # inclusive on end
S = startId:endId
currConditionDf = cbind(S, currConditionDf)
} else {
S = 1:numResponsesPerCondition
currConditionDf = cbind(S, currConditionDf)
}
rownames(currConditionDf) = NULL # need to reset row index
# check that condition's number lines up with its number in condStrNumMap
# NOTE: since condStrNumMap was created from conditionsDf, the value for a condition in condStrNumMap should be the same as
# the index of the row in conditionsDf that contains that condition.
# assert this is true in each iteration.
currConditionStr = paste((unlist(currConditionRow, use.names = FALSE)), collapse = ",")
correctConditionNumber = condStrNumMap[[currConditionStr]]
if(i != correctConditionNumber){
stop("Condition order in makeOneDataSet does not match up with condition order in condStrNumMap")
}
# add Numi and Stri to to metaLogRow
metaLogRow[[paste("Num", i, sep="")]] = i
# log strings names with space since csv
metaLogRow[[paste("Str", i, sep="")]] = paste((unlist(currConditionRow, use.names = FALSE)), collapse = " ")
#  for condition get latent mean and sd for latent mean
# e.g. latent mean pulled from y = normal(m, s). return y and s.
latentMeanAndSd = getLatentMeanAndSd(infoFilename, metaLogRow, i)
latentMean = latentMeanAndSd[["latentMean"]] # argument to link function (maybe adding offsets). used to be currMeanSeed
trueSd = latentMeanAndSd[["trueSd"]] # will get response ~ p(mu, trueSd) used to be sdSeed.
metaLogRow = latentMeanAndSd[["metaLogRow"]]
# latent mean sd is same for all conditions.
# latentMeanSd var is defined outside the loop. Update its value here.
if(i == 1){
latentMeanSd = latentMeanAndSd[["latentMeanSd"]] # latentMean = Normal(m, latentMeanSd)
}
# trueSd is one value, but it is same for all rows in this condition.
# temporarily add it to data so can use it when get new y
trueSdVec = rep(trueSd, numResponsesPerCondition)
currConditionDf[["trueSd"]] = trueSdVec
# latent mean is one value, but is same for all rows in this condition.
# vector c(latentMean, latentMean,...)
latentMeanVec = rep(latentMean, numResponsesPerCondition)
currConditionDf[["latentMean"]] = latentMeanVec
infoFileWritten <<- TRUE
# add currConditionDf to data
data = rbind(data, currConditionDf)
}
# WITHIN SUBJECTS could have just random offsets, or random offsets and random slopes.
if(!between){
# Random offsets
# if within subjects, each participant needs a random offset to add to all its latent means
# this gives each participant a different random intercept.
randomInterceptResult = addRandomIntercepts(data, metaLogRow, latentMeanSd)
metaLogRow = randomInterceptResult[["metaLogRow"]]
data = randomInterceptResult[["data"]]
}
# apply link function
data = applyLinkFunction(data)
# get new y
data = getNewY(data)
rownames(data) = NULL
# columns of data are lists right now. Need to convert to traditional data frame
data <- as.data.frame(lapply(data, unlist))
# set factor and subject columns of data to factors
data[,1:(ncol(data)-1)] <- lapply(data[,1:(ncol(data)-1)], as.factor)
return(list("data" = data, "metaLogRow" = metaLogRow))
}
# make data frame with one row per condition
# to be used for
# RETURNS: data frame with one row pers condition
makeConditionsDf <- function(numFactors, numLevelsPerFactor){
levels = list() #c[0] will be a vector with all levels of factor 1 etc
asciiA = 97
for(factor in 0:(numFactors-1)){
currLevels = list()
# make list of str levels for each factor
for(level in 0:(numLevelsPerFactor-1)){
currLevelInt = asciiA + (factor*numLevelsPerFactor) + level
currLevelStr = intToUtf8(currLevelInt)
currLevels[[(level + 1)]] = currLevelStr
} # end loop through levels for one factor
# add list of str levels for one factor to levels list
levels[[factor+1]] = currLevels
}# end loop through factors
# make data frame with each row as a new condition
conditionsDf = expand.grid(levels)
# fix colnames of conditionsDf
colNames = c()
for(i in 1:numFactors){
factorStrName = paste("X", i, sep="")
colNames = c(colNames, factorStrName)
}
colnames(conditionsDf) = colNames
return(conditionsDf)
}
# metaLogRow has Data_Set, Num_Responses_per_Condition, BW,
# Msi, SDsi for newY conditions
# Mi, SDi for newY conditions but values are NA
# add Numi, Stri, for non newY conditions
# add entries for Mi and SDi for non newY conditions but values are NA
appendToMetaLogRow = function(metaLogRow, condStrNumMap, numConditions){
# sort condStrNumMap
sortedCondStrNumMap = sort(values(condStrNumMap))
# get rid of first numConditions elements in sorted map
prunedCondStrNumMap = tail(sortedCondStrNumMap, (length(sortedCondStrNumMap)-numConditions))
# iterate through remaining conditions, log Numi, Stri, Mi, Sdi
for(i in 1:length(prunedCondStrNumMap)){
# log Numi and Stri
Numi = prunedCondStrNumMap[[i]]
Stri = names(prunedCondStrNumMap)[[i]]
correctLogIndex = numConditions + i # start from one after conditions that were logged earlier
metaLogRow[[paste("Num", correctLogIndex, sep="")]] = Numi
metaLogRow[[paste("Str", correctLogIndex, sep="")]] = Stri
# set mi and sdi but make them NA.
# then later when analyzing one factor subset, calculate means and sds and log them
# NOTE: need to make them NA so order will be
# Numi, Stri, Mi, SDi, Num(i+1), Str(i+1), M(i+1), SD(i+1), ...
metaLogRow[[paste("M", correctLogIndex, sep="")]] = NA
metaLogRow[[paste("SD", correctLogIndex, sep="")]] = NA
}
metaLogRow
}
####### END MAKE DATA #######
# create and analyze one data frame
# log results
makeAndAnalyzeOneDataSet <- function(resultsLogFilename, infoFilename, dataFrameNum, between, testType,
conditionsDf, condStrNumMap){
numResponsesPerConditionOptions = c(8,16,24,32,40) # will pick one of these options
# randomly pick num responses per condition from options
numResponsesPerCondition = sample(numResponsesPerConditionOptions, 1)
numConditions = nrow(conditionsDf) # number of conditions that newY will be pulled for
makeOneDataSetResult = makeOneDataSet(infoFilename, dataFrameNum, between, testType, conditionsDf, numConditions, numResponsesPerCondition, condStrNumMap)
data = makeOneDataSetResult[["data"]]
metaLogRow = makeOneDataSetResult[["metaLogRow"]]
# Now has all info except Mi and SDi.
metaLogRow = appendToMetaLogRow(metaLogRow, condStrNumMap, numConditions)
analyzeOneDataSet(data, dataFrameNum, between, resultsLogFilename, numResponsesPerCondition, condStrNumMap, metaLogRow) # test data in "data" dataframe
} # end makeAndAnalyzeOneDataSet)
####### END MAKE AND ANALYZE DATA #######
####### MAIN #######
# for each subset of factors, each combination of levels with exactly
# one level from each factor is assigned a unique number. key is str, value is num
# e.g. Str2 = "a c"-> condStrNumMap[["a,c"]] = 2
# Note: numbers are assigned to conditions in descending order by number of factors involved
#   i.e. conditions with levels from 3 factors have smaller numbers than conditions with levels from 2 factors
# clear and reset here
getCondStrNumMap = function(conditionsDf, numFactors, numLevelsPerFactor){
condStrNumMap = hash()
# get all factor subsets (powerset of factor names)
# sorted in descending order by number of factors in subset
factorNames = colnames(conditionsDf)
# list of vectors. elems of each vector are names of factors in subset
allFactorSubsetsUnsorted = powerset(factorNames)
# in decreasing order by number of factors in subset (ie subsets with most factors first)
# need conditions is largest number of factors to have smallest numbers since need to log seeds
allFactorSubsets= allFactorSubsetsUnsorted[order(sapply(allFactorSubsetsUnsorted,length),decreasing=T)]
# iterate through all factor subsets
currId = 1 # id for current condition
for(factorSubset in allFactorSubsets){
# get subset of conditionsDf only containing cols from factorSubset
subsetConditionsDf = conditionsDf[factorSubset]
# get rid of duplicate rows
# every condition with factors in factorSubset is represented by exactly one row in subsetConditionsDfUnique
subsetConditiondDfUnique = unique(subsetConditionsDf)
# add entry to condStrNumMap for each row in subsetConditiondDfUnique
# e.g. row = c("a", "b"), key = "a,b". value = next available value
for(row in 1:nrow(subsetConditiondDfUnique)){
# get row
currRow = subsetConditiondDfUnique[row,]
# make key
currKey = paste((unlist(currRow, use.names = FALSE)), collapse = ",")
# add entry
condStrNumMap[[currKey]] = currId
# increment id
currId = currId + 1
} # end iterate through conditions
} # end iterate through factor subsets
condStrNumMap # return
} # end function
# makes directory for test type and returns path to dir
getTestTypeDir = function(parentDirPath, testType){
# make dir
dirName = paste(parentDirPath, testType, sep="/")
dir.create(dirName)
# return
dirName
}
# makes directory for design and returns path to dir
getDesignDirPath = function(parentDirPath, numFactors, numLevelsPerFactor){
# e.g. numFactors = 2, numLevelsPerFactor = 3 -> "3x3"
designStr = paste(rep(numLevelsPerFactor, numFactors), collapse="x")
dirName = paste(parentDirPath, designStr, sep="/")
# make dir
dir.create(dirName)
# return
dirName
}
# creates string name for path to info file and returns it
getInfoFilename <- function(parentDirPath, testType){
infoFilename = paste(parentDirPath, "/", "info-", testType, ".txt", sep="") # full file name
infoFilename
}
# makes directory for between/within and returns path to dir
getBetweenDirPath = function(parentDirPath, between){
betweenStr = if(between) "between" else "within"
dirName = paste(parentDirPath, "/", betweenStr, sep="")
# create dir
dir.create(dirName)
# return
dirName
}
# Note: this gets called after get info file name (since info file same for between and and within, but log separate)
getResultsLogFilename = function(parentDirPath, numFactors, numLevelsPerFactor, between, testType){
# e.g. numFactors = 3, numLevelsPerFactor = 2 -> 2x2x2
levelsStr = paste(replicate(numFactors, numLevelsPerFactor), collapse="x")
# between = TRUE -> "between", between = FALSE -> "within"
betweenStr = if (between) "between" else "within"
# testType is global
resultsLogFilename = paste(parentDirPath, "/results-log-", levelsStr,  "-type-", testType, "-", betweenStr, ".csv", sep="") # full file name
resultsLogFilename
}
#### NEW MAINLOOP
mainLoop<- function(testType, timeStampStr, testDirPath){
# make directory for logs for this test type. return path to dir.
testTypeDirPath = getTestTypeDir(testDirPath, testType)
# get info file path.
infoFilename = getInfoFilename(testTypeDirPath, testType)
infoFileWritten <<- FALSE
designs = list(list("numFactors" = 2, "numLevelsPerFactor" = 2),
list("numFactors" = 3, "numLevelsPerFactor" = 2),
list("numFactors" = 2, "numLevelsPerFactor" = 3)
)
for(design in designs){
numFactors = design[["numFactors"]]
numLevelsPerFactor = design[["numLevelsPerFactor"]]
# make directory for logs for this design. return path to dir.
designDirPath = getDesignDirPath(testTypeDirPath, numFactors, numLevelsPerFactor)
# data frame with 1 row per condition. same for all data sets with current design.
conditionsDf = makeConditionsDf(numFactors, numLevelsPerFactor)
# e.g. Str2 = "a c"-> condStrNumMap[["a,c"]] = 2
# Note: use comma in R since that's how contrasts print
#       ues space when logging since don't want to use comma in csv
# Note: numbers are assigned to conditions in descending order by number of factors involved
#   i.e. conditions with levels from 3 factors have smaller numbers than conditions with levels from 2 factors
condStrNumMap = getCondStrNumMap(conditionsDf, numFactors, numLevelsPerFactor)
for(between in c(TRUE, FALSE)){
# reset since separate logs for between and within
dataFrameNum = 1 # local
trialNum <<- 1 # global
# between subjects logs and within subjects logs in different directories
# this is the path to that directory
betweenDirPath = getBetweenDirPath(designDirPath, between)
# log file name
resultsLogFilename = getResultsLogFilename(betweenDirPath, numFactors, numLevelsPerFactor, between, testType)
for(i in 1:numDataSets){
if((i-1)%%25 == 0){ # print every 25 data sets
cat("test type")
print(testType)
cat("design")
print(paste(rep(numLevelsPerFactor, numFactors), collapse='x'))
cat("between")
print(between)
cat("test #")
print(i)
cat("\n")
}
makeAndAnalyzeOneDataSet(resultsLogFilename, infoFilename, dataFrameNum, between, testType,
conditionsDf, condStrNumMap) # one data data frame
dataFrameNum  = dataFrameNum + 1
} # end iterate through all data sets
} # end between and within
}
}
#### END NEW MAINLOOP
# makes directory for results from this test and return path
getTestDir = function(timeStampStr){
# logs dir doesn't already exist, make it
if(!dir.exists("logs")){
dir.create("logs")
}
# make dir
# it won't already exist since based on system time
dirName = paste("logs/test-", timeStampStr, sep="")
dir.create(dirName)
# return
dirName
}
# globals
trialNum = 1
numDataSets = 2
randomSeed = 1
infoFileWritten = FALSE # new info file for every testType x Design
warningCt = 0 # number of times we get a warning
# useful for link functions and pulling from distrs
normalDistrs = c(0,1,100,101)
logNormalDistrs = c(10,11,110,111)
exponentialDistrs = c(20,120)
cauchyDistrs = c(30,31,130,131,132)
threeDfTDistrs = c(40,41,140,141,142)
doubleExponentialDistrs = c(50,51,150,151)
# NOTE no 21 or 121 because exponential only has one param
#testTypes = c(normalDistrs,logNormalDistrs,exponentialDistrs,cauchyDistrs,threeDfTDistrs,doubleExponentialDistrs)
testTypes = c(30,132)
testType = 0 # make explicitly global since running inside function now
# Second arg doesn't matter. we're not doing ordered contrasts.
options(contrasts=c("contr.sum", "contr.sum"))
# get testTypes from command line
# if no args supplied, use default testTypes above (is all test types)
args=(commandArgs(TRUE))
if(length(args) > 0){
testTypes = sapply(parse(text = args), eval)
}
runTest = function(){
emm_options(sep=",")
# results dir path and time for this test
timeStamp = as.character(Sys.time()) # timestamp for log file name
timeStampStr = str_replace_all(timeStamp, c(":" = "-", " " = "-"))
# path to directory for results from this test
testDirPath = getTestDir(timeStampStr)
for(localTestType in testTypes){
set.seed(randomSeed) # set random seed at start of each test type
testType <<- localTestType
suppressMessages(mainLoop(localTestType, timeStampStr, testDirPath))
}
}
runTest()
